{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reinforcement Learning for Stock Market Trader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas_datareader as data_reader\n",
    "\n",
    "from tqdm import tqdm_notebook, tqdm\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0-beta1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the AI Trader Network\n",
    "\n",
    "- action_space = 3 : Stay, Buy, Sell\n",
    "- state 는 지나간 날들과 그 날의 주가 이다.  \n",
    "- loss 를 mse 를 사용할 것이므로 linear activation 사용 \n",
    "    - we will modify our actions with our rewards which is a continuous number and not a class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AI_Trader:\n",
    "    \n",
    "    def __init__(self, state_size, action_space=3, model_name=\"AITrader\"):\n",
    "    \n",
    "        self.state_size = state_size\n",
    "        self.action_space = action_space\n",
    "        self.memory = deque(maxlen=2000)      # for memory replay\n",
    "        self.inventory = []                                  # stock inventory\n",
    "        self.model_name = model_name\n",
    "\n",
    "        self.gamma = 0.95\n",
    "        self.epsilon = 1.0                                  # 처음에는 100% random\n",
    "        self.epsilon_final = 0.01                        \n",
    "        self.epsilon_decay = 0.995                     # how fast epsilon decays\n",
    "\n",
    "        self.model = self.model_builder()\n",
    "        \n",
    "    def model_builder(self):\n",
    "        model = tf.keras.models.Sequential()\n",
    "        model.add(Dense(units=32, activation='relu', input_dim=self.state_size))\n",
    "        model.add(Dense(units=64, activation='relu'))\n",
    "        model.add(Dense(units=128, activation='relu'))\n",
    "        model.add(Dense(units=self.action_space, activation='linear'))     # loss 를 mse 를 사용할 것이므로 linear activation 사용\n",
    "        model.compile(loss='mse', optimizer=tf.keras.optimizers.Adam(lr=0.001))\n",
    "        return model\n",
    "        \n",
    "    def trader(self, state):\n",
    "        if random.random() <= self.epsilon:\n",
    "            return random.randrange(self.action_space)   # 0, 1, 2  : compleately random policy\n",
    "        \n",
    "        actions = self.model.predict(state)\n",
    "        return np.argmax(actions[0])\n",
    "    \n",
    "    # Custom Trading function\n",
    "    def batch_train(self, batch_size):\n",
    "        batch = []\n",
    "        for i in range(len(self.memory) - batch_size + 1, len(self.memory)):  # memory 뒤에서 batch_size 개 만큼부터 사용\n",
    "            batch.append(self.memory[i])\n",
    "            \n",
    "        for state, action, reward, next_state, done in batch:\n",
    "            reward = reward   # if terminal state\n",
    "            if not done:         \n",
    "                reward = reward + self.gamma * np.amax(self.model.predict(next_state)[0])   #amax - maximum value\n",
    "                \n",
    "            target = self.model.predict(state)\n",
    "            target[0][action] = reward\n",
    "            \n",
    "            self.model.fit(state, target, epochs=1, verbose=0)\n",
    "            \n",
    "            if self.epsilon > self.epsilon_final:\n",
    "                self.epsilon *= self.epsilon_decay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions\n",
    "\n",
    "- Sigmoid\n",
    "\n",
    "    - 주가가 200 에서 1000 으로 뛰는 것과 40 에서 200 으로 뛰는 것을 같은 차이로 scale 하기 위해 사용\n",
    "    \n",
    "- stock_price_format\n",
    "    - 주식을 사고, 팔때의 가격 formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1+math.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stocks_price_format(n):\n",
    "    if n < 0:\n",
    "        return \"- $ {0:2f}\".format(abs(n))\n",
    "    else:\n",
    "        return \" $ {0:2f}\".format(abs(n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Yahoo Finance \n",
    "https://finance.yahoo.com/quote/AAPL?p=AAPL&.tsrc=fin-srch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Adj Close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2009-12-31</th>\n",
       "      <td>30.478571</td>\n",
       "      <td>30.080000</td>\n",
       "      <td>30.447144</td>\n",
       "      <td>30.104286</td>\n",
       "      <td>88102700.0</td>\n",
       "      <td>26.372231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-04</th>\n",
       "      <td>30.642857</td>\n",
       "      <td>30.340000</td>\n",
       "      <td>30.490000</td>\n",
       "      <td>30.572857</td>\n",
       "      <td>123432400.0</td>\n",
       "      <td>26.782711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-05</th>\n",
       "      <td>30.798571</td>\n",
       "      <td>30.464285</td>\n",
       "      <td>30.657143</td>\n",
       "      <td>30.625713</td>\n",
       "      <td>150476200.0</td>\n",
       "      <td>26.829010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-06</th>\n",
       "      <td>30.747143</td>\n",
       "      <td>30.107143</td>\n",
       "      <td>30.625713</td>\n",
       "      <td>30.138571</td>\n",
       "      <td>138040000.0</td>\n",
       "      <td>26.402260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-07</th>\n",
       "      <td>30.285715</td>\n",
       "      <td>29.864286</td>\n",
       "      <td>30.250000</td>\n",
       "      <td>30.082857</td>\n",
       "      <td>119282800.0</td>\n",
       "      <td>26.353460</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 High        Low       Open      Close       Volume  Adj Close\n",
       "Date                                                                          \n",
       "2009-12-31  30.478571  30.080000  30.447144  30.104286   88102700.0  26.372231\n",
       "2010-01-04  30.642857  30.340000  30.490000  30.572857  123432400.0  26.782711\n",
       "2010-01-05  30.798571  30.464285  30.657143  30.625713  150476200.0  26.829010\n",
       "2010-01-06  30.747143  30.107143  30.625713  30.138571  138040000.0  26.402260\n",
       "2010-01-07  30.285715  29.864286  30.250000  30.082857  119282800.0  26.353460"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = data_reader.DataReader(\"AAPL\", data_source=\"yahoo\")\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2009-12-31', '00:00:00']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(dataset.index[0]).split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data loading from yahoo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_loader(stock_name):\n",
    "    dataset = data_reader.DataReader(stock_name, data_source=\"yahoo\")\n",
    "    start_date = str(dataset.index[0]).split()[0]\n",
    "    end_date = str(dataset.index[-1]).split()[0]\n",
    "    close = dataset['Close']\n",
    "    return close"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## state 생성자\n",
    "- timestep : 현재의 time step\n",
    "- window_size : 이전 몇일치 주가로 예측할지 time window\n",
    "\n",
    "### agent 가 어떤 action 을 취하는지와 무관하게 state 는 random 하게 변화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def state_creator(data, timestep=0, window_size=10):\n",
    "    \n",
    "    starting_id = timestep - window_size + 1      # timestep 으로부터 window_size 이전 만큼에서 starting \n",
    "    \n",
    "    if starting_id >=0:                                         # starting 시점이 window_size 보다 클 경우 \n",
    "        windowed_data = data[starting_id:timestep+1]       # window_size 이전 부터 현재 timestep 까지의 data\n",
    "    else:\n",
    "        windowed_data = - starting_id * [data[0]] + list(data[0:timestep+1])    # window_size 보다 작은 data 는 시작 data 로 padding\n",
    "\n",
    "    state = []                   \n",
    "    for i in range(window_size - 1):\n",
    "        state.append(sigmoid(windowed_data[i+1] - windowed_data[i]))\n",
    "    \n",
    "    return np.array([state])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dataset loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_name = \"AAPL\"\n",
    "data = dataset_loader(stock_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training AI Trader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 10\n",
    "episodes = 1000\n",
    "batch_size = 32\n",
    "data_samples = len(data) - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 32)                352       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 11,171\n",
      "Trainable params: 11,171\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "trader = AI_Trader(window_size)\n",
    "trader.model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for episode in range(1, episodes + 1):\n",
    "    print(\"Episode: {}/{}\".format(episode, episodes))\n",
    "    \n",
    "    state = state_creator(data, 0, window_size + 1)        # start 는 처음 data 부터\n",
    "    \n",
    "    total_profit = 0\n",
    "    trader.inventory = []                                               # 처음에는 보유 stock 없음\n",
    "    \n",
    "    for t in tqdm(range(data_samples)):\n",
    "        \n",
    "        action = trader.trader(state)\n",
    "        \n",
    "        next_state = state_creator(data, t+1, window_size + 1)\n",
    "        reward = 0\n",
    "        \n",
    "        if action == 1:   # Buying\n",
    "            trader.inventory.append(data[t])\n",
    "            print(\"AI trader bought: \", stocks_price_format(data[t]))\n",
    "        elif action == 2 and len(trader.inventory) > 0:\n",
    "            buy_price = trader.inventory.pop(0)\n",
    "            reward = max(data[t] - buy_price, 0)\n",
    "            total_profit += data[t] - buy_price\n",
    "            print(\"AI trader sold: \", stocks_price_format(data[t]), \"Profit: \" + stocks_price_format(data[t] - buy_price) )\n",
    "            \n",
    "        if t == data_samples - 1:\n",
    "            done = True\n",
    "        else:\n",
    "            done = False\n",
    "            \n",
    "        trader.memory.append((state, action, reward, next_state, done))\n",
    "        \n",
    "        state = next_state\n",
    "        \n",
    "        if done:\n",
    "            print(\"########################\")\n",
    "            print(\"TOTAL PROFIT: {}\".format(total_profit))\n",
    "            print(\"########################\")\n",
    "        \n",
    "        if len(trader.memory) > batch_size:\n",
    "            trader.batch_train(batch_size)\n",
    "        \n",
    "        if episode % 10 == 0:\n",
    "            trader.model.save(\"AI_trader_{}.h5\".format(episode))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
